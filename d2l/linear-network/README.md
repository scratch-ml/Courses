## 线性回归
回归（regression）是能为一个或多个自变量与因变量之间关系建模的一类方法，回归经常用来表示输入和输出之间的关系，例如预测一个值。
线性回归有四大要素：
- 线性模型：自变量和因变量之间的关系是线性的，即可以表示为：$$y = \omega_1 x_1 + \omega_2 x_2 + \cdots + \omega_n x_n + b$$
- 损失函数：衡量预测值和真实值之间的差异，例如平方损失函数：$$l(y, \hat{y}) = (y - \hat{y})^2$$
- 优化算法：如何找到最优的参数，例如梯度下降法：$$\omega_i = \omega_i - \eta \frac{\partial l}{\partial \omega_i}$$
- 评估指标：衡量模型的好坏，例如均方误差：$$MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$$
定义好这四大要素即可构造线性回归模型

注：
- 每个输入都与每个输出相连，我们将这种变换称为全连接层（fully‐connected layer）或称为稠密层（dense layer）
- 线性回归模型中，输入和输出是标量，因此线性回归的输出层是一个标量。







## 线性回归的从零开始实现

## 线性回归的简洁实现

